{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597004367080",
   "display_name": "Python 3.7.3 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando base de dados\n",
    "base = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando dados e classe (Feature, Target)\n",
    "preditos = base.data\n",
    "classe = base.target\n",
    "\n",
    "# Fazendo One-Hot Encoding (Dummy variable)\n",
    "classe_dummy = np_utils.to_categorical(classe)\n",
    "\n",
    "# Dividindo base entre treino e teste\n",
    "X_training, X_test, y_training, y_test = train_test_split(preditos, classe_dummy, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando modelo de treinamento e teste\n",
    "modelo = Sequential()\n",
    "\n",
    "# Adicionando ao modelo camada oculta com 5 neurônios e 4 neurônios na camada de entrada\n",
    "modelo.add(Dense(units = 5, input_dim = 4))\n",
    "\n",
    "# Adicionando ao modelo camada oculta com 4 neurônios\n",
    "modelo.add(Dense(units = 4))\n",
    "\n",
    "# Adicionando ao modelo camada de saída com 3 neurônios\n",
    "modelo.add(Dense(units = 3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 5)                 25        \n_________________________________________________________________\ndense_1 (Dense)              (None, 4)                 24        \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 15        \n=================================================================\nTotal params: 64\nTrainable params: 64\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Resumo do modelo criado\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "l_loss: 0.1559 - val_accuracy: 0.9556\nEpoch 861/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9905 - val_loss: 0.1585 - val_accuracy: 0.9556\nEpoch 862/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9905 - val_loss: 0.1631 - val_accuracy: 0.9556\nEpoch 863/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9905 - val_loss: 0.1634 - val_accuracy: 0.9556\nEpoch 864/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0434 - accuracy: 0.9905 - val_loss: 0.1564 - val_accuracy: 0.9556\nEpoch 865/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 0.9905 - val_loss: 0.1553 - val_accuracy: 0.9556\nEpoch 866/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0442 - accuracy: 0.9905 - val_loss: 0.1566 - val_accuracy: 0.9556\nEpoch 867/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0438 - accuracy: 0.9905 - val_loss: 0.1581 - val_accuracy: 0.9556\nEpoch 868/1000\n4/4 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9905 - val_loss: 0.1667 - val_accuracy: 0.9556\nEpoch 869/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0438 - accuracy: 0.9905 - val_loss: 0.1733 - val_accuracy: 0.9556\nEpoch 870/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.9905 - val_loss: 0.1755 - val_accuracy: 0.9556\nEpoch 871/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9905 - val_loss: 0.1666 - val_accuracy: 0.9556\nEpoch 872/1000\n4/4 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9905 - val_loss: 0.1615 - val_accuracy: 0.9556\nEpoch 873/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0439 - accuracy: 0.9905 - val_loss: 0.1651 - val_accuracy: 0.9556\nEpoch 874/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9905 - val_loss: 0.1629 - val_accuracy: 0.9556\nEpoch 875/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9905 - val_loss: 0.1652 - val_accuracy: 0.9556\nEpoch 876/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1595 - val_accuracy: 0.9556\nEpoch 877/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9905 - val_loss: 0.1524 - val_accuracy: 0.9333\nEpoch 878/1000\n4/4 [==============================] - 0s 6ms/step - loss: 0.0461 - accuracy: 0.9905 - val_loss: 0.1509 - val_accuracy: 0.9333\nEpoch 879/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0452 - accuracy: 0.9905 - val_loss: 0.1537 - val_accuracy: 0.9333\nEpoch 880/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9905 - val_loss: 0.1603 - val_accuracy: 0.9556\nEpoch 881/1000\n4/4 [==============================] - 0s 6ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1691 - val_accuracy: 0.9556\nEpoch 882/1000\n4/4 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9905 - val_loss: 0.1764 - val_accuracy: 0.9556\nEpoch 883/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9905 - val_loss: 0.1780 - val_accuracy: 0.9556\nEpoch 884/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9905 - val_loss: 0.1743 - val_accuracy: 0.9556\nEpoch 885/1000\n4/4 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9905 - val_loss: 0.1686 - val_accuracy: 0.9556\nEpoch 886/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9905 - val_loss: 0.1676 - val_accuracy: 0.9556\nEpoch 887/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9905 - val_loss: 0.1680 - val_accuracy: 0.9556\nEpoch 888/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1638 - val_accuracy: 0.9556\nEpoch 889/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1541 - val_accuracy: 0.9333\nEpoch 890/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.9905 - val_loss: 0.1515 - val_accuracy: 0.9333\nEpoch 891/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0443 - accuracy: 0.9905 - val_loss: 0.1571 - val_accuracy: 0.9556\nEpoch 892/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9905 - val_loss: 0.1675 - val_accuracy: 0.9556\nEpoch 893/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0423 - accuracy: 0.9905 - val_loss: 0.1724 - val_accuracy: 0.9556\nEpoch 894/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9905 - val_loss: 0.1741 - val_accuracy: 0.9556\nEpoch 895/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9905 - val_loss: 0.1706 - val_accuracy: 0.9556\nEpoch 896/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 0.1551 - val_accuracy: 0.9333\nEpoch 897/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9905 - val_loss: 0.1497 - val_accuracy: 0.9111\nEpoch 898/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0463 - accuracy: 0.9905 - val_loss: 0.1501 - val_accuracy: 0.9111\nEpoch 899/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9905 - val_loss: 0.1538 - val_accuracy: 0.9333\nEpoch 900/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1585 - val_accuracy: 0.9556\nEpoch 901/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9905 - val_loss: 0.1697 - val_accuracy: 0.9556\nEpoch 902/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.9905 - val_loss: 0.1754 - val_accuracy: 0.9556\nEpoch 903/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9905 - val_loss: 0.1791 - val_accuracy: 0.9556\nEpoch 904/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 0.9905 - val_loss: 0.1744 - val_accuracy: 0.9556\nEpoch 905/1000\n4/4 [==============================] - 0s 6ms/step - loss: 0.0425 - accuracy: 0.9905 - val_loss: 0.1691 - val_accuracy: 0.9556\nEpoch 906/1000\n4/4 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9905 - val_loss: 0.1627 - val_accuracy: 0.9556\nEpoch 907/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0424 - accuracy: 0.9905 - val_loss: 0.1596 - val_accuracy: 0.9556\nEpoch 908/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9905 - val_loss: 0.1620 - val_accuracy: 0.9556\nEpoch 909/1000\n4/4 [==============================] - 0s 9ms/step - loss: 0.0425 - accuracy: 0.9905 - val_loss: 0.1584 - val_accuracy: 0.9556\nEpoch 910/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9905 - val_loss: 0.1615 - val_accuracy: 0.9556\nEpoch 911/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9905 - val_loss: 0.1683 - val_accuracy: 0.9556\nEpoch 912/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9905 - val_loss: 0.1741 - val_accuracy: 0.9556\nEpoch 913/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1696 - val_accuracy: 0.9556\nEpoch 914/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1645 - val_accuracy: 0.9556\nEpoch 915/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9905 - val_loss: 0.1644 - val_accuracy: 0.9556\nEpoch 916/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9905 - val_loss: 0.1638 - val_accuracy: 0.9556\nEpoch 917/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9905 - val_loss: 0.1629 - val_accuracy: 0.9556\nEpoch 918/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9905 - val_loss: 0.1614 - val_accuracy: 0.9556\nEpoch 919/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9905 - val_loss: 0.1655 - val_accuracy: 0.9556\nEpoch 920/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9905 - val_loss: 0.1678 - val_accuracy: 0.9556\nEpoch 921/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1725 - val_accuracy: 0.9556\nEpoch 922/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.9905 - val_loss: 0.1734 - val_accuracy: 0.9556\nEpoch 923/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.9905 - val_loss: 0.1737 - val_accuracy: 0.9556\nEpoch 924/1000\n4/4 [==============================] - 0s 10ms/step - loss: 0.0422 - accuracy: 0.9905 - val_loss: 0.1703 - val_accuracy: 0.9556\nEpoch 925/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9905 - val_loss: 0.1675 - val_accuracy: 0.9556\nEpoch 926/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9905 - val_loss: 0.1626 - val_accuracy: 0.9556\nEpoch 927/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9905 - val_loss: 0.1610 - val_accuracy: 0.9556\nEpoch 928/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9905 - val_loss: 0.1624 - val_accuracy: 0.9556\nEpoch 929/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.1660 - val_accuracy: 0.9556\nEpoch 930/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9905 - val_loss: 0.1664 - val_accuracy: 0.9556\nEpoch 931/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.9905 - val_loss: 0.1639 - val_accuracy: 0.9556\nEpoch 932/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9905 - val_loss: 0.1611 - val_accuracy: 0.9556\nEpoch 933/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9905 - val_loss: 0.1624 - val_accuracy: 0.9556\nEpoch 934/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0410 - accuracy: 0.9905 - val_loss: 0.1641 - val_accuracy: 0.9556\nEpoch 935/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9905 - val_loss: 0.1664 - val_accuracy: 0.9556\nEpoch 936/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9905 - val_loss: 0.1669 - val_accuracy: 0.9556\nEpoch 937/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9905 - val_loss: 0.1679 - val_accuracy: 0.9556\nEpoch 938/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0407 - accuracy: 0.9905 - val_loss: 0.1601 - val_accuracy: 0.9556\nEpoch 939/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.9905 - val_loss: 0.1575 - val_accuracy: 0.9556\nEpoch 940/1000\n1/4 [======>.......................] - ETA: 0s - loss: 0.0083 - accuracy: 1.004/4 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9905 - val_loss: 0.1570 - val_accuracy: 0.9556\nEpoch 941/1000\n4/4 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9905 - val_loss: 0.1527 - val_accuracy: 0.9333\nEpoch 942/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9905 - val_loss: 0.1552 - val_accuracy: 0.9333\nEpoch 943/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9905 - val_loss: 0.1569 - val_accuracy: 0.9556\nEpoch 944/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9905 - val_loss: 0.1599 - val_accuracy: 0.9556\nEpoch 945/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9905 - val_loss: 0.1651 - val_accuracy: 0.9556\nEpoch 946/1000\n4/4 [==============================] - 0s 11ms/step - loss: 0.0410 - accuracy: 0.9905 - val_loss: 0.1705 - val_accuracy: 0.9556\nEpoch 947/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0423 - accuracy: 0.9905 - val_loss: 0.1754 - val_accuracy: 0.9556\nEpoch 948/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.1649 - val_accuracy: 0.9556\nEpoch 949/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 0.9905 - val_loss: 0.1575 - val_accuracy: 0.9556\nEpoch 950/1000\n4/4 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9905 - val_loss: 0.1541 - val_accuracy: 0.9333\nEpoch 951/1000\n4/4 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.1594 - val_accuracy: 0.9556\nEpoch 952/1000\n4/4 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 0.9905 - val_loss: 0.1660 - val_accuracy: 0.9556\nEpoch 953/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0407 - accuracy: 0.9905 - val_loss: 0.1714 - val_accuracy: 0.9556\nEpoch 954/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.9905 - val_loss: 0.1733 - val_accuracy: 0.9556\nEpoch 955/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0416 - accuracy: 0.9905 - val_loss: 0.1724 - val_accuracy: 0.9556\nEpoch 956/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9905 - val_loss: 0.1704 - val_accuracy: 0.9556\nEpoch 957/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 0.1664 - val_accuracy: 0.9556\nEpoch 958/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 0.9905 - val_loss: 0.1638 - val_accuracy: 0.9556\nEpoch 959/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9905 - val_loss: 0.1631 - val_accuracy: 0.9556\nEpoch 960/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9905 - val_loss: 0.1616 - val_accuracy: 0.9556\nEpoch 961/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0403 - accuracy: 0.9905 - val_loss: 0.1620 - val_accuracy: 0.9556\nEpoch 962/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0407 - accuracy: 0.9905 - val_loss: 0.1646 - val_accuracy: 0.9556\nEpoch 963/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9905 - val_loss: 0.1654 - val_accuracy: 0.9556\nEpoch 964/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9905 - val_loss: 0.1646 - val_accuracy: 0.9556\nEpoch 965/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9905 - val_loss: 0.1651 - val_accuracy: 0.9556\nEpoch 966/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.1679 - val_accuracy: 0.9556\nEpoch 967/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0406 - accuracy: 0.9905 - val_loss: 0.1590 - val_accuracy: 0.9556\nEpoch 968/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9905 - val_loss: 0.1566 - val_accuracy: 0.9333\nEpoch 969/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 0.9905 - val_loss: 0.1596 - val_accuracy: 0.9556\nEpoch 970/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9905 - val_loss: 0.1558 - val_accuracy: 0.9333\nEpoch 971/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9905 - val_loss: 0.1557 - val_accuracy: 0.9333\nEpoch 972/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9905 - val_loss: 0.1575 - val_accuracy: 0.9556\nEpoch 973/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0405 - accuracy: 0.9905 - val_loss: 0.1546 - val_accuracy: 0.9333\nEpoch 974/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9905 - val_loss: 0.1548 - val_accuracy: 0.9333\nEpoch 975/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.1561 - val_accuracy: 0.9333\nEpoch 976/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 0.1543 - val_accuracy: 0.9333\nEpoch 977/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9905 - val_loss: 0.1545 - val_accuracy: 0.9333\nEpoch 978/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9905 - val_loss: 0.1574 - val_accuracy: 0.9556\nEpoch 979/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0400 - accuracy: 0.9905 - val_loss: 0.1633 - val_accuracy: 0.9556\nEpoch 980/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9905 - val_loss: 0.1701 - val_accuracy: 0.9556\nEpoch 981/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9905 - val_loss: 0.1744 - val_accuracy: 0.9556\nEpoch 982/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.1725 - val_accuracy: 0.9556\nEpoch 983/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0423 - accuracy: 0.9905 - val_loss: 0.1615 - val_accuracy: 0.9556\nEpoch 984/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9905 - val_loss: 0.1599 - val_accuracy: 0.9556\nEpoch 985/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0398 - accuracy: 0.9905 - val_loss: 0.1597 - val_accuracy: 0.9556\nEpoch 986/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9905 - val_loss: 0.1600 - val_accuracy: 0.9556\nEpoch 987/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9905 - val_loss: 0.1591 - val_accuracy: 0.9556\nEpoch 988/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9905 - val_loss: 0.1611 - val_accuracy: 0.9556\nEpoch 989/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9905 - val_loss: 0.1667 - val_accuracy: 0.9556\nEpoch 990/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9905 - val_loss: 0.1666 - val_accuracy: 0.9556\nEpoch 991/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9905 - val_loss: 0.1645 - val_accuracy: 0.9556\nEpoch 992/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9905 - val_loss: 0.1648 - val_accuracy: 0.9556\nEpoch 993/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0396 - accuracy: 0.9905 - val_loss: 0.1636 - val_accuracy: 0.9556\nEpoch 994/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 0.9905 - val_loss: 0.1630 - val_accuracy: 0.9556\nEpoch 995/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 0.9905 - val_loss: 0.1624 - val_accuracy: 0.9556\nEpoch 996/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 0.9905 - val_loss: 0.1604 - val_accuracy: 0.9556\nEpoch 997/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9905 - val_loss: 0.1544 - val_accuracy: 0.9333\nEpoch 998/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0432 - accuracy: 0.9905 - val_loss: 0.1522 - val_accuracy: 0.9111\nEpoch 999/1000\n4/4 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.1567 - val_accuracy: 0.9333\nEpoch 1000/1000\n4/4 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 0.9905 - val_loss: 0.1662 - val_accuracy: 0.9556\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1434475c0>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Compilando Rede Neural - ajuste dos pessos, cálculo de erros e resultado\n",
    "modelo.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Treinando modelo\n",
    "modelo.fit(X_training, y_training, epochs = 1000, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[16,  0,  0],\n       [ 0, 16,  0],\n       [ 0,  0, 13]])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Testando modelo\n",
    "previsoes = modelo.predict(X_test)\n",
    "previsoes = (previsoes > 0.5)\n",
    "\n",
    "# Gerando matriz de confusão\n",
    "y_test_matrix = [np.argmax(t) for t in y_test]\n",
    "y_previsao_matrix = [np.argmax(t) for t in previsoes]\n",
    "confusao = confusion_matrix(y_previsao_matrix, y_previsao_matrix)\n",
    "confusao"
   ]
  }
 ]
}